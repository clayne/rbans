{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os, math, sys, re\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext import vocab\n",
    "\n",
    "# Import model and model helper functions\n",
    "sys.path.append(\"..\")\n",
    "import src.fasttext as ft\n",
    "import src.fasttext_utils as ftu\n",
    "\n",
    "seed = 2019\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "data_dir = '../data'  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "max_vocab_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the structure of the text data\n",
    "TEXT = data.Field(\n",
    "    sequential=True,\n",
    "    preprocessing=ftu.generate_bigrams,\n",
    "    tokenize=ftu.reg_tokenize,\n",
    "    lower=True)\n",
    "\n",
    "LABEL = data.Field(\n",
    "    dtype = torch.float,\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    pad_token=None, \n",
    "    unk_token=None)\n",
    "\n",
    "nn_fields = [(\"id\", None),\n",
    "              (\"score\", None),\n",
    "              (\"body\", TEXT),\n",
    "              (\"label\", LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting sets into train test and validate + preprocessing and tokenizing\n",
    "train, validate, test = data.TabularDataset.splits(\n",
    "    path=data_dir,\n",
    "    train='main_train_subsample.csv',\n",
    "    validation=\"main_validate_subsample.csv\",\n",
    "    test='main_test_subsample.csv',\n",
    "    format='csv',\n",
    "    skip_header=False, \n",
    "    fields=nn_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained embeddings from twitter data\n",
    "vec = vocab.Vectors('glove.twitter.27B.100d.txt', os.path.join(data_dir, 'embeddings'))\n",
    "\n",
    "# Build our corpus of vocabulary\n",
    "TEXT.build_vocab(train, max_size=max_vocab_size, vectors=vec, unk_init=torch.Tensor.normal_)\n",
    "with open(os.path.join(data_dir, 'model/NN_fasttext_data.pkl'), 'wb') as output:\n",
    "    pickle.dump(TEXT, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch each set for processing via our model\n",
    "train_iter, validate_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, validate, test), batch_size=batch_size,\n",
    "    sort_key=lambda x: len(x.body),\n",
    "    device=device, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,000,301 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with the following params\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_weights = TEXT.vocab.vectors\n",
    "embedding_dim = 100\n",
    "output_dim = 1\n",
    "padding_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model = ft.FastText(vocab_size, embedding_dim, output_dim, embedding_weights, padding_idx, unk_idx)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "model = model.to(device)\n",
    "loss = loss.to(device)\n",
    "\n",
    "print(f'The model has {ftu.count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Idx: 5000, Training Loss: 0.4069, Training Accuracy:  85.94%\n",
      "Epoch: 1, Idx: 10000, Training Loss: 0.4712, Training Accuracy:  79.69%\n",
      "Epoch: 1, Idx: 15000, Training Loss: 0.4087, Training Accuracy:  81.25%\n",
      "Epoch: 1, Idx: 20000, Training Loss: 0.3913, Training Accuracy:  82.81%\n",
      "Epoch: 1, Idx: 25000, Training Loss: 0.4141, Training Accuracy:  84.38%\n",
      "Epoch: 1, Idx: 30000, Training Loss: 0.4258, Training Accuracy:  81.25%\n",
      "Epoch: 1, Idx: 35000, Training Loss: 0.2668, Training Accuracy:  84.38%\n",
      "Epoch: 1, Idx: 40000, Training Loss: 0.2886, Training Accuracy:  92.19%\n",
      "Epoch: 1, Idx: 45000, Training Loss: 0.4043, Training Accuracy:  82.81%\n",
      "Epoch: 1, Idx: 50000, Training Loss: 0.4627, Training Accuracy:  84.38%\n",
      "Epoch: 1, Idx: 55000, Training Loss: 0.3428, Training Accuracy:  82.81%\n",
      "Epoch: 1, Idx: 60000, Training Loss: 0.3542, Training Accuracy:  84.38%\n",
      "Epoch: 1, Idx: 65000, Training Loss: 0.4533, Training Accuracy:  85.94%\n",
      "Epoch: 1, Idx: 70000, Training Loss: 0.3558, Training Accuracy:  85.94%\n",
      "Epoch: 1, Idx: 75000, Training Loss: 0.3504, Training Accuracy:  87.50%\n",
      "Epoch: 01 | Epoch Time: 28m 58s | Train Loss: 0.393 | Train Acc: 83.56%\n",
      "Epoch: 2, Idx: 5000, Training Loss: 0.3827, Training Accuracy:  84.38%\n",
      "Epoch: 2, Idx: 10000, Training Loss: 0.3375, Training Accuracy:  84.38%\n",
      "Epoch: 2, Idx: 15000, Training Loss: 0.5995, Training Accuracy:  73.44%\n",
      "Epoch: 2, Idx: 20000, Training Loss: 0.3140, Training Accuracy:  87.50%\n",
      "Epoch: 2, Idx: 25000, Training Loss: 0.4351, Training Accuracy:  79.69%\n",
      "Epoch: 2, Idx: 30000, Training Loss: 0.3770, Training Accuracy:  89.06%\n",
      "Epoch: 2, Idx: 35000, Training Loss: 0.4193, Training Accuracy:  81.25%\n",
      "Epoch: 2, Idx: 40000, Training Loss: 0.4264, Training Accuracy:  79.69%\n",
      "Epoch: 2, Idx: 45000, Training Loss: 0.3784, Training Accuracy:  85.94%\n",
      "Epoch: 2, Idx: 50000, Training Loss: 0.5911, Training Accuracy:  71.88%\n",
      "Epoch: 2, Idx: 55000, Training Loss: 0.3264, Training Accuracy:  87.50%\n",
      "Epoch: 2, Idx: 60000, Training Loss: 0.2477, Training Accuracy:  89.06%\n",
      "Epoch: 2, Idx: 65000, Training Loss: 0.4178, Training Accuracy:  82.81%\n",
      "Epoch: 2, Idx: 70000, Training Loss: 0.2881, Training Accuracy:  87.50%\n",
      "Epoch: 2, Idx: 75000, Training Loss: 0.4113, Training Accuracy:  79.69%\n",
      "Epoch: 02 | Epoch Time: 28m 32s | Train Loss: 0.378 | Train Acc: 84.31%\n",
      "Epoch: 3, Idx: 5000, Training Loss: 0.3051, Training Accuracy:  90.62%\n",
      "Epoch: 3, Idx: 10000, Training Loss: 0.4463, Training Accuracy:  85.94%\n",
      "Epoch: 3, Idx: 15000, Training Loss: 0.2934, Training Accuracy:  89.06%\n",
      "Epoch: 3, Idx: 20000, Training Loss: 0.4679, Training Accuracy:  87.50%\n",
      "Epoch: 3, Idx: 25000, Training Loss: 0.3793, Training Accuracy:  82.81%\n",
      "Epoch: 3, Idx: 30000, Training Loss: 0.3836, Training Accuracy:  87.50%\n",
      "Epoch: 3, Idx: 35000, Training Loss: 0.3237, Training Accuracy:  85.94%\n",
      "Epoch: 3, Idx: 40000, Training Loss: 0.4580, Training Accuracy:  81.25%\n",
      "Epoch: 3, Idx: 45000, Training Loss: 0.5202, Training Accuracy:  75.00%\n",
      "Epoch: 3, Idx: 50000, Training Loss: 0.3566, Training Accuracy:  84.38%\n",
      "Epoch: 3, Idx: 55000, Training Loss: 0.3505, Training Accuracy:  79.69%\n",
      "Epoch: 3, Idx: 60000, Training Loss: 0.4973, Training Accuracy:  78.12%\n",
      "Epoch: 3, Idx: 65000, Training Loss: 0.2731, Training Accuracy:  92.19%\n",
      "Epoch: 3, Idx: 70000, Training Loss: 0.4416, Training Accuracy:  84.38%\n",
      "Epoch: 3, Idx: 75000, Training Loss: 0.4243, Training Accuracy:  82.81%\n",
      "Epoch: 03 | Epoch Time: 29m 2s | Train Loss: 0.376 | Train Acc: 84.38%\n",
      "Epoch: 4, Idx: 5000, Training Loss: 0.4663, Training Accuracy:  76.56%\n",
      "Epoch: 4, Idx: 10000, Training Loss: 0.2951, Training Accuracy:  87.50%\n",
      "Epoch: 4, Idx: 15000, Training Loss: 0.5002, Training Accuracy:  79.69%\n",
      "Epoch: 4, Idx: 20000, Training Loss: 0.4798, Training Accuracy:  81.25%\n",
      "Epoch: 4, Idx: 25000, Training Loss: 0.3578, Training Accuracy:  85.94%\n",
      "Epoch: 4, Idx: 30000, Training Loss: 0.3311, Training Accuracy:  84.38%\n",
      "Epoch: 4, Idx: 35000, Training Loss: 0.4611, Training Accuracy:  76.56%\n",
      "Epoch: 4, Idx: 40000, Training Loss: 0.4976, Training Accuracy:  75.00%\n",
      "Epoch: 4, Idx: 45000, Training Loss: 0.2636, Training Accuracy:  92.19%\n",
      "Epoch: 4, Idx: 50000, Training Loss: 0.4429, Training Accuracy:  78.12%\n",
      "Epoch: 4, Idx: 55000, Training Loss: 0.3593, Training Accuracy:  82.81%\n",
      "Epoch: 4, Idx: 60000, Training Loss: 0.4104, Training Accuracy:  82.81%\n",
      "Epoch: 4, Idx: 65000, Training Loss: 0.2839, Training Accuracy:  89.06%\n",
      "Epoch: 4, Idx: 70000, Training Loss: 0.3705, Training Accuracy:  81.25%\n",
      "Epoch: 4, Idx: 75000, Training Loss: 0.3871, Training Accuracy:  87.50%\n",
      "Epoch: 04 | Epoch Time: 30m 37s | Train Loss: 0.375 | Train Acc: 84.41%\n",
      "Epoch: 5, Idx: 5000, Training Loss: 0.3929, Training Accuracy:  87.50%\n",
      "Epoch: 5, Idx: 10000, Training Loss: 0.3068, Training Accuracy:  87.50%\n",
      "Epoch: 5, Idx: 15000, Training Loss: 0.4878, Training Accuracy:  76.56%\n",
      "Epoch: 5, Idx: 20000, Training Loss: 0.3766, Training Accuracy:  81.25%\n",
      "Epoch: 5, Idx: 25000, Training Loss: 0.3225, Training Accuracy:  90.62%\n",
      "Epoch: 5, Idx: 30000, Training Loss: 0.2442, Training Accuracy:  92.19%\n",
      "Epoch: 5, Idx: 35000, Training Loss: 0.2921, Training Accuracy:  85.94%\n",
      "Epoch: 5, Idx: 40000, Training Loss: 0.4694, Training Accuracy:  85.94%\n",
      "Epoch: 5, Idx: 45000, Training Loss: 0.2787, Training Accuracy:  92.19%\n",
      "Epoch: 5, Idx: 50000, Training Loss: 0.4401, Training Accuracy:  81.25%\n",
      "Epoch: 5, Idx: 55000, Training Loss: 0.2696, Training Accuracy:  92.19%\n",
      "Epoch: 5, Idx: 60000, Training Loss: 0.4659, Training Accuracy:  76.56%\n",
      "Epoch: 5, Idx: 65000, Training Loss: 0.3575, Training Accuracy:  85.94%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start_time = time.time() \n",
    "        \n",
    "    train_loss, train_acc = ft.train_model(model, train_iter, optim, loss, epoch)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = ft.epoch_time(start_time, end_time)\n",
    "    torch.save(model, os.path.join(data_dir, 'model/NN_fasttext_model.pt'))\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_loss, validate_acc = ft.evaluate_model(model, validate_iter, loss)\n",
    "print(f'Val. Loss: {validate_loss:.3f} | Val. Acc: {validate_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = ft.evaluate_model(model, validate_iter, loss)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cuda_9.0]",
   "language": "python",
   "name": "conda-env-pytorch_cuda_9.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
