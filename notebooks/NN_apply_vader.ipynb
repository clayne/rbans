{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import csv\n",
    "import os, sys, re\n",
    "import ast\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from itertools import product\n",
    "\n",
    "# Import model and model helper functions\n",
    "sys.path.append(\"..\")\n",
    "import src.fasttext as ft\n",
    "import src.fasttext_utils as ftu\n",
    "from src.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "Reading english - 2grams ...\n",
      "Reading english - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "ekphrasis_processor = TextPreProcessor(\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'date', 'number'],  # normalize terms\n",
    "    fix_html=True,  # fix HTML tokens  \n",
    "    segmenter=\"english\",  # corpus for word segmentation\n",
    "    corrector=\"english\",  # corpus for spell correction\n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # unpack contractions \n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    tokenizer=ftu.reg_tokenize,\n",
    "    dicts=[emoticons]  # replace emojis with words\n",
    ")\n",
    "\n",
    "def compound_analyzer(sentence):\n",
    "    try:\n",
    "        return analyzer.polarity_scores(sentence)['compound']\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def model_preprocess(sentence):\n",
    "    tokenized = ftu.generate_bigrams([tok.lower() for tok in ekphrasis_processor.pre_process_doc(sentence)])\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050\n"
     ]
    }
   ],
   "source": [
    "def apply_vader(file):\n",
    "    chunksize = 100000\n",
    "    start_row = int(float(file[0:4]) * chunksize)\n",
    "    if start_row == 0:\n",
    "        start_row = 1\n",
    "    filename = \"applied/\" + str(file[5:])\n",
    "    applied_data = os.path.join(data_dir, filename)\n",
    "    chunk = pd.read_csv(\n",
    "        applied_data, skiprows=start_row, nrows=chunksize,\n",
    "        names=[\"id\", \"date\", \"author\", \"subreddit\", \"body\"],\n",
    "        dtype={\"id\": str, \"date\": str, \"author\": str, \"subreddit\": str, \"body\": str},\n",
    "    )\n",
    "    chunk[\"sentiment\"] = chunk.body.map(compound_analyzer)\n",
    "    chunk[\"body\"] = chunk.body.map(model_preprocess)\n",
    "    chunk.to_csv(\n",
    "        os.path.join(data_dir, \"split/\" + file),\n",
    "        quoting=csv.QUOTE_NONNUMERIC,\n",
    "        header=False, index=False\n",
    "    )\n",
    "\n",
    "file_list = os.listdir(os.path.join(data_dir, 'applied/'))\n",
    "chnk_list = [str(x).zfill(4) + \"_\" for x in range(101)]\n",
    "all_jobs = [''.join(x) for x in list(product(chnk_list, file_list))]    \n",
    "\n",
    "completed_jobs = os.listdir(os.path.join(data_dir, 'split/'))\n",
    "\n",
    "jobs = set(all_jobs) - set(completed_jobs)\n",
    "jobs = [x for x in jobs if x[-4:] == \".csv\"]\n",
    "\n",
    "print(len(jobs))\n",
    "pool = Pool(24)\n",
    "pool.map(apply_vader, jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cuda_9.0]",
   "language": "python",
   "name": "conda-env-pytorch_cuda_9.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
