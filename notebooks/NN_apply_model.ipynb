{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import csv\n",
    "import os, math, sys\n",
    "import string\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext import vocab\n",
    "from itertools import product\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "# Import model and model helper functions\n",
    "sys.path.append(\"..\")\n",
    "import src.fasttext as ft\n",
    "import src.fasttext_utils as ftu\n",
    "from src.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "data_dir = '../data'  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the following params\n",
    "model = torch.load(os.path.join(data_dir, 'model/NN_fasttext_model.pt'))\n",
    "model.eval()\n",
    "with open(os.path.join(data_dir, 'model/NN_fasttext_data.pkl'), 'rb') as input:\n",
    "    TEXT = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "Reading english - 2grams ...\n",
      "Reading english - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "ekphrasis_processor = TextPreProcessor(\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'date', 'number'],  # normalize terms\n",
    "    fix_html=True,  # fix HTML tokens  \n",
    "    segmenter=\"english\",  # corpus for word segmentation\n",
    "    corrector=\"english\",  # corpus for spell correction\n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # unpack contractions \n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    tokenizer=ftu.reg_tokenize,\n",
    "    dicts=[emoticons]  # replace emojis with words\n",
    ")\n",
    "\n",
    "\n",
    "def predict_from_preprocessed(sentence):\n",
    "    tokenized = ast.literal_eval(sentence)\n",
    "    if len(tokenized) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "        tensor = torch.LongTensor(indexed).to(device)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "        return prediction.item()\n",
    "    \n",
    "    \n",
    "def predict_from_sentence(sentence):\n",
    "    tokenized = ftu.generate_bigrams([tok.lower() for tok in ekphrasis_processor.pre_process_doc(sentence)])\n",
    "    if len(tokenized) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "        tensor = torch.LongTensor(indexed).to(device)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "        return prediction.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is hate speech!\n"
     ]
    }
   ],
   "source": [
    "sent = \"\"\"I hate jews and hilary clinton\"\"\"\n",
    "\n",
    "if predict_from_sentence(sent) == 1.0:\n",
    "    print(\"This is hate speech!\")\n",
    "else:\n",
    "    print(\"This is not hate speech!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_chunks(filelist):\n",
    "    file_date = filelist[0][-11:-4]\n",
    "    df = pd.concat((pd.read_csv(\n",
    "        file,\n",
    "        names=[\"id\", \"date\", \"author\", \"subreddit\", \"body\", \"sentiment\"],\n",
    "        dtype={\"id\": str, \"date\": str, \"author\": str, \"subreddit\": str, \"body\": str, \"sentiment\": float},\n",
    "        ) for file in filelist)) \n",
    "    print(\"Finished concatenating\", file_date)\n",
    "    df[\"classification\"] = df.body.map(predict_from_preprocessed)\n",
    "    print(\"Finished classifying\", file_date)\n",
    "    df[\"is_hate\"] = (df.classification == 1.0) & (df.sentiment < -0.05).astype(int)\n",
    "    df.drop(columns=[\"body\", \"id\"], inplace=True)\n",
    "    df.to_csv(\n",
    "        os.path.join(data_dir, \"analysis/concat_applied_data_\" + file_date + \".csv\"),\n",
    "        quoting=csv.QUOTE_NONNUMERIC,\n",
    "        header=True, index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_jobs = os.listdir(os.path.join(data_dir, 'split/'))\n",
    "\n",
    "batch = []\n",
    "for year in range(2015, 2020):\n",
    "    for month in range(1, 13):\n",
    "        batch.append([\n",
    "            os.path.join(data_dir, 'split/' + x) for\n",
    "            x in completed_jobs if x[-11:-4] == str(year) + '_' + str(month).zfill(2)])\n",
    "        \n",
    "batch = [x for x in batch if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished concatenating 2019_02\n",
      "Finished classifying 2019_02\n"
     ]
    }
   ],
   "source": [
    "concat_chunks(batch[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cuda_9.0]",
   "language": "python",
   "name": "conda-env-pytorch_cuda_9.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
