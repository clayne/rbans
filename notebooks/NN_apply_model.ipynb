{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os, math, sys\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext import vocab\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "# Import model and model helper functions\n",
    "sys.path.append(\"..\")\n",
    "from src.fasttext_utils import *\n",
    "from src.fasttext import *\n",
    "    \n",
    "data_dir = '../data'  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the following params\n",
    "model = torch.load(os.path.join(data_dir, 'model/NN_fasttext_model.pt'))\n",
    "model.eval()\n",
    "with open(os.path.join(data_dir, 'model/NN_fasttext_data.pkl'), 'rb') as input:\n",
    "    TEXT = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_sentence(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = generate_bigrams([tok for tok in SocialTokenizer(lowercase=True).tokenize(sentence)])\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "    return prediction.item()\n",
    "\n",
    "\n",
    "def predict_from_batch(sentence):\n",
    "    model.eval()\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in sentence]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_from_sentence(model, 'Some of them Im sure are good people. Both sides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [(predict_from_batch(x.body), x.body) for i, x in enumerate(test) if int(x.label) == 1]\n",
    "print(temp_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cuda_9.0]",
   "language": "python",
   "name": "conda-env-pytorch_cuda_9.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
