{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os, math\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext import vocab\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "\n",
    "seed = 2019\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "data_dir = '/home/dfsnow/rbans/data'  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "max_vocab_size = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some user-defined helper functions\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()  \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = generate_bigrams([tok for tok in SocialTokenizer(lowercase=True).tokenize(sentence)])\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the structure of the text data\n",
    "TEXT = data.Field(\n",
    "    sequential=True,\n",
    "    preprocessing=generate_bigrams,\n",
    "    tokenize=SocialTokenizer(lowercase=True).tokenize,\n",
    "    lower=True)\n",
    "\n",
    "LABEL = data.Field(\n",
    "    dtype=torch.float,\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    pad_token=None, \n",
    "    unk_token=None)\n",
    "\n",
    "rnn_fields = [(\"id\", None),\n",
    "              (\"score\", None),\n",
    "              (\"body\", TEXT),\n",
    "              (\"label\", LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting sets into train test and validate + preprocessing and tokenizing\n",
    "train, validate, test = data.TabularDataset.splits(\n",
    "    path=data_dir,\n",
    "    train='test_train.csv',\n",
    "    validation=\"test_validate.csv\",\n",
    "    test='test_test.csv',\n",
    "    format='csv',\n",
    "    skip_header=False, \n",
    "    fields=rnn_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch each set for processing via our model\n",
    "train_iter, validate_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, validate, test), batch_size=batch_size,\n",
    "    sort_key=lambda x: len(x.body), device=device,\n",
    "    repeat=False, shuffle=True)\n",
    "\n",
    "# Load pre-trained embeddings from twitter data\n",
    "vec = vocab.Vectors('glove.twitter.27B.100d.txt', os.path.join(data_dir, 'embeddings'))\n",
    "\n",
    "# Build our corpus of vocabulary\n",
    "TEXT.build_vocab(train, validate, max_size=max_vocab_size, vectors=vec, unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FastText model outlined in this notebook:\n",
    "# https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb\n",
    "# and further described in this paper:\n",
    "# https://arxiv.org/abs/1607.01759\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, embedding_weights, padding_idx):\n",
    "        super().__init__()      \n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_weights = embedding_weights\n",
    "        self.output_dim = output_dim\n",
    "        self.padding_idx = padding_idx\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.embeddings.weight.data.copy_(embedding_weights)\n",
    "        self.embeddings.weight.data[TEXT.vocab.stoi[TEXT.unk_token]] = torch.zeros(embedding_dim)\n",
    "        self.embeddings.weight.data[padding_idx] = torch.zeros(embedding_dim)\n",
    "        \n",
    "        self.label = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "         \n",
    "        embedded = self.embeddings(text)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "               \n",
    "        return self.label(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_iter, optim, loss_func, epoch):\n",
    "    \n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        optim.zero_grad()\n",
    "        batch_size = batch.body.size()[1]  # subsetting to fix a weird DataParallel bug\n",
    "        predictions = model(batch.body).squeeze(1)\n",
    "        loss = loss_func(predictions[0:batch_size], batch.label)  \n",
    "        acc = binary_accuracy(predictions[0:batch_size], batch.label)      \n",
    "        loss.backward()     \n",
    "        optim.step()\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_acc += acc.item()\n",
    "        \n",
    "    return total_epoch_loss / len(train_iter), total_epoch_acc / len(train_iter)\n",
    "\n",
    "\n",
    "def evaluate_model(model, validate_iter, loss_func):\n",
    "    \n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(validate_iter):\n",
    "            batch_size = batch.body.size()[1]  \n",
    "            predictions = model(batch.body).squeeze(1)\n",
    "            loss = loss_func(predictions[0:batch_size], batch.label)  \n",
    "            acc = binary_accuracy(predictions[0:batch_size], batch.label) \n",
    "\n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc.item()\n",
    "        \n",
    "    return total_epoch_loss / len(validate_iter), total_epoch_acc / len(validate_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the following params\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_weights = TEXT.vocab.vectors\n",
    "embedding_dim = 100\n",
    "output_dim = 1\n",
    "padding_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = FastText(vocab_size, embedding_dim, output_dim, embedding_weights, padding_idx)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs for modelling...\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "model = model.to(device)\n",
    "loss = loss.to(device)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start_time = time.time() \n",
    "    \n",
    "    train_loss, train_acc = train_model(model, train_iter, optim, loss, epoch)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    \n",
    "validate_loss, validate_acc = evaluate_model(model, validate_iter, loss)\n",
    "print(f'Val. Loss: {validate_loss:.3f} |  Val. Acc: {validate_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"I really didn't like that movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    model.eval()\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in sentence]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = (torch.sigmoid(model(tensor)) > 0.5)\n",
    "    return prediction.item()\n",
    "\n",
    "temp_list = [(predict_sentiment(x.body), x.body) for i, x in enumerate(test) if int(x.label) == 1]\n",
    "#temp_list = [predict_sentiment(x.body) for i, x in enumerate(test)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cuda_9.0]",
   "language": "python",
   "name": "conda-env-pytorch_cuda_9.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
